fastapi

uvicorn[standard]==0.29.0

sentence-transformers==2.7.0

transformers==4.46.3

faiss-cpu==1.8.0.post1

scikit-learn==1.5.2

numpy==1.26.4

pydantic==2.7.1

googletrans

tqdm==4.67.1

regex==2024.11.6

requests==2.32.3

huggingface-hub==0.25.2

safetensors==0.4.5

tokenizers==0.20.3

diskcache>=5.6.1

gradio>=4.44.0


--extra-index-url https://download.pytorch.org/whl/cpu \
--extra-index-url https://abetlen.github.io/llama-cpp-python/whl/cpu


llama-cpp-python
